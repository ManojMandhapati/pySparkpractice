{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c62f0504-3e25-445a-85f1-a1816bd8df9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Problem \n",
    "You have a Dataframe containing customer transaction information. Each row contains details of a customer, including multiple transactions stored in a nested array structure. Your goal is to transform the data to create summary columns for each customer, such as number of transactions, total spend, and the most recent transaction date.\n",
    "\n",
    "# 𝘚𝘢𝘮𝘱𝘭𝘦 𝘥𝘢𝘵𝘢\n",
    "𝘥𝘢𝘵𝘢 = [\n",
    " (1, [{\"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘪𝘥\": 101, \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘥𝘢𝘵𝘦\": \"2024-01-10\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘢𝘮𝘰𝘶𝘯𝘵\": 50.0}, {\"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘪𝘥\": 102, \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘥𝘢𝘵𝘦\": \"2024-02-15\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘢𝘮𝘰𝘶𝘯𝘵\": 100.0}]),\n",
    " (2, [{\"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘪𝘥\": 103, \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘥𝘢𝘵𝘦\": \"2024-03-01\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘢𝘮𝘰𝘶𝘯𝘵\": 75.0}]),\n",
    " (3, [{\"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘪𝘥\": 104, \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘥𝘢𝘵𝘦\": \"2023-12-20\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘢𝘮𝘰𝘶𝘯𝘵\": 120.0}, {\"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘪𝘥\": 105, \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘥𝘢𝘵𝘦\": \"2024-01-25\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘢𝘮𝘰𝘶𝘯𝘵\": 200.0}, {\"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘪𝘥\": 106, \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘥𝘢𝘵𝘦\": \"2024-02-10\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯_𝘢𝘮𝘰𝘶𝘯𝘵\": 90.0}])\n",
    "]\n",
    "\n",
    "# 𝘋𝘦𝘧𝘪𝘯𝘦 𝘴𝘤𝘩𝘦𝘮𝘢\n",
    "𝘤𝘰𝘭𝘶𝘮𝘯𝘴 = [\"𝘤𝘶𝘴𝘵𝘰𝘮𝘦𝘳_𝘪𝘥\", \"𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯𝘴\"]\n",
    "\n",
    "# 𝘊𝘳𝘦𝘢𝘵𝘦 𝘋𝘢𝘵𝘢𝘍𝘳𝘢𝘮𝘦\n",
    "𝘥𝘧 = 𝘴𝘱𝘢𝘳𝘬.𝘤𝘳𝘦𝘢𝘵𝘦𝘋𝘢𝘵𝘢𝘍𝘳𝘢𝘮𝘦(𝘥𝘢𝘵𝘢, 𝘤𝘰𝘭𝘶𝘮𝘯𝘴)\n",
    "\n",
    "## Expected Outcome:\n",
    "+-----------+-----------------+------------------------+--------------------+\n",
    "|customer_id|transaction_count|total_transaction_amount|max_transaction_date|\n",
    "+-----------+-----------------+------------------------+--------------------+\n",
    "|          1|                2|                   150.0|          2024-02-15|\n",
    "|          2|                1|                    75.0|          2024-03-01|\n",
    "|          3|                3|                   320.0|          2024-12-20|\n",
    "+-----------+-----------------+------------------------+--------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8435b60a-9a27-4be8-9c5e-eaf1d6b4b5da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructField, StructType, ArrayType, FloatType, Inter\n",
    "from pyspark.sql.functions import explode, col, count, sum, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56cee7a4-b458-4007-9663-b99fb6333c64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transaction_schema = ArrayType(\n",
    "  StructType().add(field = 'transaction_id',data_type=IntegerType())\\\n",
    "    .add(field='transaction_date', data_type=StringType())\\\n",
    "      .add(field='transcation_amount', data_type=FloatType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b49203dc-4f9f-446d-8491-80d906ee3ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType().add(field= 'customer_id',data_type=IntegerType())\\\n",
    "  .add(field = 'transactions',data_type = transaction_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577c174f-747a-4970-80db-f45d3222e38f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "  (1, [{'transaction_id':101, 'transaction_date':'2024-01-10', 'transcation_amount':50.0},\n",
    "       {'transaction_id':102, 'transaction_date':'2024-02-15', 'transcation_amount':100.0}]),\n",
    " (2, [{'transaction_id':103, 'transaction_date':'2024-03-01', 'transcation_amount':75.0}]),\n",
    "  (3, [{'transaction_id':104, 'transaction_date':'2024-12-20', 'transcation_amount':120.0},\n",
    "       {'transaction_id':105, 'transaction_date':'2024-01-25', 'transcation_amount':200.0},\n",
    "       {'transaction_id':106, 'transaction_date':'2024-02-10', 'transcation_amount':00.0}]),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900ba623-810c-4ab5-9142-94c87525bfc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------------------------------------------------------+\n|customer_id|transactions                                                                |\n+-----------+----------------------------------------------------------------------------+\n|1          |[{101, 2024-01-10, 50.0}, {102, 2024-02-15, 100.0}]                         |\n|2          |[{103, 2024-03-01, 75.0}]                                                   |\n|3          |[{104, 2024-12-20, 120.0}, {105, 2024-01-25, 200.0}, {106, 2024-02-10, 0.0}]|\n+-----------+----------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data,schema)\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "007e7a04-a18a-47b8-b656-d957348f2ea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------------+\n|customer_id|transaction_date|transaction_amount|\n+-----------+----------------+------------------+\n|          1|      2024-01-10|              50.0|\n|          1|      2024-02-15|             100.0|\n|          2|      2024-03-01|              75.0|\n|          3|      2024-12-20|             120.0|\n|          3|      2024-01-25|             200.0|\n|          3|      2024-02-10|               0.0|\n+-----------+----------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Explode the transactions array\n",
    "explode_df = df.withColumn('docs', explode(col('transactions')))\\\n",
    "    .select('customer_id',\n",
    "            col('docs.transaction_date').alias('transaction_date'),  # Correct field name\n",
    "            col('docs.transcation_amount').alias('transaction_amount'))  # Correct field name\n",
    "\n",
    "explode_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99514b8f-01da-4ab0-b4ac-c7069d8041a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------------------+--------------------+\n|customer_id|transaction_count|total_transaction_amount|max_transaction_date|\n+-----------+-----------------+------------------------+--------------------+\n|          1|                2|                   150.0|          2024-02-15|\n|          2|                1|                    75.0|          2024-03-01|\n|          3|                3|                   320.0|          2024-12-20|\n+-----------+-----------------+------------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Perform aggregation\n",
    "result_df = explode_df.groupBy('customer_id')\\\n",
    "    .agg(\n",
    "        count('transaction_amount').alias('transaction_count'),\n",
    "        sum('transaction_amount').alias('total_transaction_amount'),\n",
    "        max('transaction_date').alias('max_transaction_date')\n",
    "    )\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a87b0161-5287-4892-94ed-3bc8a0dc3648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "LinkedIn Transformation Problem1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
