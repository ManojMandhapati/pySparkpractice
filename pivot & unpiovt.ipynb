{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b084ec-65d8-4342-9667-39e691649a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Pivot is used to rotate data in one column into multiple columns.\n",
    "It is an aggregation where one of the grouping column values will be conerted into multiple values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e427da-1479-4fa6-b0aa-61a5c8fd9b7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1,'manoj','male',3000,'DE'),(2,'megha','female',4000,'QA'),(3,'Naveen','male',5000,'QA'),(4,'Manasa','female',6000,'Payroll'),(5,'manoj','male',3000,'DE'),(6,'megha','female',4000,'QA'),(7,'Naveen','male',5000,'QA'),(8,'Manasa','female',6000,'Payroll')]\n",
    "schema = ['id','name','gender','salay','dept']\n",
    "df= spark.createDataFrame(data,schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a639c25f-5b8c-455c-bec4-e2980ed3d777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n|   dept|gender|count|\n+-------+------+-----+\n|     DE|  male|    2|\n|     QA|female|    2|\n|     QA|  male|    2|\n|Payroll|female|    2|\n+-------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept,df.gender).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d02acfe-f38b-4847-9afd-23afea7bfdf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----+\n|   dept|female|male|\n+-------+------+----+\n|Payroll|     2|null|\n|     DE|  null|   2|\n|     QA|     2|   2|\n+-------+------+----+\n\n+-------+----+\n|   dept|male|\n+-------+----+\n|Payroll|null|\n|     DE|   2|\n|     QA|   2|\n+-------+----+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('dept').pivot('gender').count().show()\n",
    "df.groupBy('dept').pivot('gender',['male']).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fec0363-cc9a-4bff-bbaf-e0e28075704f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Unpioting is rotating columns into rows. Pyspark SQL doesn't have unpivot function hence we will use stack() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a4076fd-f2e7-47d4-9e75-335fb7ee37e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [('IT',8,5), ('Payroll',3,4),('HR',4,3)]\n",
    "schema = ['dept','male','female']\n",
    "df = spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5277f3bb-c8d3-4b9d-bc03-339a23d80ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n|   dept|gender|count|\n+-------+------+-----+\n|     IT|  Male|    8|\n|     IT|Female|    5|\n|Payroll|  Male|    3|\n|Payroll|Female|    4|\n|     HR|  Male|    4|\n|     HR|Female|    3|\n+-------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import expr\n",
    "df.select( 'dept',expr(\"stack(2,'Male',male,'Female',female)as (gender, count)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c45dd6a0-2156-4bc9-a511-fd3c0d9d96ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pivot & unpiovt",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
